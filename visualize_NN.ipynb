{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import copy\n",
    "from torch.utils.data import DataLoader,  TensorDataset\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import data_challenge_library as dcl\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import utility_library as ulb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Table has 446487 sources\n",
      "Keeping 432767 labeled sources\n",
      "Keeping only the required 62 features\n",
      "Keeping 142963 with all features available\n",
      "Keeping 142963 with available cutouts\n",
      "class\n",
      "Star    56532\n",
      "Gal     53331\n",
      "Qso     32780\n",
      "Agn       320\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "object_table = dcl.load_table(features = \"Savic\", have_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning train, validation and test objects\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = dcl.prepare_sample(object_table)\n",
    "train.get_images(dcl.load_images(train.objectID, as_tensor=True))\n",
    "test.get_images(dcl.load_images(test.objectID, as_tensor = True))\n",
    "validation.get_images(dcl.load_images(validation.objectID, as_tensor = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images in the dataset\n"
     ]
    }
   ],
   "source": [
    "train.get_dataloader(batch_size = 40)\n",
    "validation.get_dataloader(batch_size = 40)\n",
    "test.get_dataloader(batch_size = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class merged_model(nn.Module):\n",
    "    def __init__(self, process_tabular, process_image, process_flattened_image, process_both):\n",
    "        super(merged_model, self).__init__()\n",
    "\n",
    "        self.process_tabular = process_tabular\n",
    "        self.process_image = process_image\n",
    "        self.process_flattened_image = process_flattened_image\n",
    "        self.process_both = process_both\n",
    "\n",
    "    def forward(self, tabular, image):\n",
    "        image = self.process_image(image)\n",
    "        image = torch.flatten(image, start_dim = 1, end_dim = -1)\n",
    "        image = self.process_flattened_image(image)    \n",
    "        tabular = self.process_tabular(tabular)\n",
    "        \n",
    "        out = torch.concat([image, tabular], dim =1)\n",
    "        out = self.process_both(out)    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class merged_model_explicit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(merged_model_explicit, self).__init__()\n",
    "        \n",
    "        self.process_tabular = nn.Sequential(nn.Linear(62, 62, bias = True), \n",
    "                                             nn.LeakyReLU(), nn.Linear(62,30, bias=True),\n",
    "                                             nn.LeakyReLU())\n",
    "\n",
    "        self.process_image = nn.Sequential(nn.MaxPool2d(kernel_size = 2, stride = 1),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           nn.Conv2d(3, 1, kernel_size=1),  nn.LeakyReLU())\n",
    "        self.process_flattened_image = nn.Sequential(nn.Linear(225, 30), nn.LeakyReLU(),\n",
    "                                                     nn.Linear(30, 30), nn.LeakyReLU())\n",
    "        \n",
    "        self.process_both = nn.Sequential(nn.Linear(60, 30), nn.LeakyReLU(), \n",
    "                                          nn.Linear(30, 3), nn.LeakyReLU() )\n",
    "     \n",
    "\n",
    "    def forward(self, tabular, image):\n",
    "        image = self.process_image(image)\n",
    "        print(image.shape)\n",
    "        image = torch.flatten(image, start_dim = 1, end_dim = -1)\n",
    "        image = self.process_flattened_image(image)    \n",
    "        tabular = self.process_tabular(tabular)\n",
    "        \n",
    "        out = torch.concat([image, tabular], dim =1)\n",
    "        out = self.process_both(out)    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tabular = ulb.general_dense(input_size = 62, output_size = 30,  hidden_sizes =[62],\n",
    "                  activation_function = nn.LeakyReLU)\n",
    "process_image = ulb.general_convo2d(out_channels = 1, conv_kernel = 1, conv_stride = 1, conv_padding = 0,\n",
    "                             pool_kernel = 2)\n",
    "process_flattened_image = ulb.general_dense(input_size = process_image.Nout_tot, output_size = 30, \n",
    "                                                    hidden_sizes =[30])\n",
    "process_both = ulb.general_dense(input_size = 60, output_size = 3, hidden_sizes =[30])\n",
    "\n",
    "combined_model = merged_model(process_tabular, process_image, process_flattened_image, process_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_routine(dataloader, model, loss_fn, optimizer, verbose = True):\n",
    "    losses = []\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, (features, images,  labels) in enumerate(dataloader): \n",
    "        output = model(features, images)\n",
    "        loss = loss_fn(output, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()    # Clear the gradient\n",
    "        loss.backward()          # Compute the gradient (??)\n",
    "        optimizer.step()         # update model weights\n",
    "\n",
    "        \n",
    "        if batch == round(num_batches/2):\n",
    "            losses.append(loss.item())\n",
    "            if verbose:\n",
    "                print(f\"loss: {loss:>7f}\")\n",
    "\n",
    "    return losses\n",
    "\n",
    "def test_routine(dataloader, model, loss_fn, verbose = True):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for features, images, labels in dataloader:\n",
    "            output = model(features, images)\n",
    "            test_loss += loss_fn(output, labels).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    if verbose:\n",
    "        print(f\" Avg test loss      : {test_loss:>8f}\")\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "SEED = 123\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  #torch.nn.CrossEntropyLoss\n",
    "optimizer = torch.optim.SGD(combined_model.parameters(), lr=0.001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1---------------------\n",
      " Avg test loss      : 1.065625\n",
      "Epoch 2---------------------\n",
      " Avg test loss      : 0.995638\n",
      "Epoch 3---------------------\n",
      " Avg test loss      : 0.780467\n",
      "Epoch 4---------------------\n",
      " Avg test loss      : 0.596399\n",
      "Epoch 5---------------------\n",
      " Avg test loss      : 0.549283\n",
      "Epoch 6---------------------\n",
      " Avg test loss      : 0.534706\n",
      "Epoch 7---------------------\n",
      " Avg test loss      : 0.528098\n",
      "Epoch 8---------------------\n",
      " Avg test loss      : 0.524048\n",
      "Epoch 9---------------------\n",
      " Avg test loss      : 0.521516\n",
      "Epoch 10---------------------\n",
      " Avg test loss      : 0.519525\n",
      "Epoch 11---------------------\n",
      " Avg test loss      : 0.518073\n",
      "Epoch 12---------------------\n",
      " Avg test loss      : 0.516745\n",
      "Epoch 13---------------------\n",
      " Avg test loss      : 0.515742\n",
      "Epoch 14---------------------\n",
      " Avg test loss      : 0.514770\n",
      "Epoch 15---------------------\n",
      " Avg test loss      : 0.513926\n",
      "Epoch 16---------------------\n",
      " Avg test loss      : 0.513143\n",
      "Epoch 17---------------------\n",
      " Avg test loss      : 0.512444\n",
      "Epoch 18---------------------\n",
      " Avg test loss      : 0.511922\n",
      "Epoch 19---------------------\n",
      " Avg test loss      : 0.511228\n",
      "Epoch 20---------------------\n",
      " Avg test loss      : 0.510669\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss  = []\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}---------------------\")\n",
    "    train_loss.append(train_routine(train.dataloader, combined_model, loss_fn, optimizer, verbose = False))\n",
    "    test_loss.append(test_routine(validation.dataloader, combined_model, loss_fn, verbose = True))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "model = merged_model_explicit()\n",
    "batch_f, batch_i, batch_lab = next(iter(train.dataloader))\n",
    "yhat = model(batch_f, batch_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rnn_torchviz.png'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(yhat,params = dict(model.named_parameters())).render(\"rnn_torchviz\",format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process_tabular.full_sequence.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0971,  0.0882,  0.1191,  ...,  0.0964,  0.1005, -0.0140],\n",
       "          [ 0.0443,  0.1372, -0.0474,  ..., -0.0995, -0.1008,  0.0275],\n",
       "          [ 0.0921,  0.0330,  0.1203,  ..., -0.0782, -0.0305, -0.0047],\n",
       "          ...,\n",
       "          [-0.0810, -0.0962,  0.1133,  ...,  0.0230, -0.0425, -0.0936],\n",
       "          [ 0.0850,  0.0824, -0.0698,  ...,  0.0069, -0.1047,  0.0090],\n",
       "          [ 0.1174,  0.0236, -0.0436,  ..., -0.0360,  0.0243, -0.0787]],\n",
       "         requires_grad=True)),\n",
       " ('process_tabular.full_sequence.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0725,  0.1362,  0.0226, -0.0930,  0.0832,  0.0777, -0.1061,  0.1225,\n",
       "           0.0129, -0.0747, -0.0088,  0.0158, -0.0518,  0.0497,  0.0917, -0.0481,\n",
       "           0.1120, -0.0863,  0.1171, -0.0354,  0.0878, -0.0188, -0.0674, -0.0578,\n",
       "           0.0466,  0.0287, -0.0098, -0.0690,  0.1169, -0.0541, -0.0655, -0.0546,\n",
       "           0.0833,  0.1349,  0.0332,  0.0433,  0.1252,  0.1255,  0.0445, -0.0831,\n",
       "           0.1204,  0.0482,  0.0478,  0.0210,  0.1390, -0.0749,  0.0494,  0.0498,\n",
       "          -0.0790,  0.1156, -0.0532,  0.1154,  0.1456, -0.0454, -0.0388, -0.0824,\n",
       "          -0.0500,  0.1161, -0.0013, -0.0485, -0.0201, -0.1064],\n",
       "         requires_grad=True)),\n",
       " ('process_tabular.full_sequence.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0799,  0.1116,  0.0754,  ...,  0.0979, -0.0932,  0.0060],\n",
       "          [-0.1106,  0.1225, -0.0888,  ..., -0.0880, -0.0133,  0.0176],\n",
       "          [-0.1122, -0.0961,  0.0939,  ...,  0.0551,  0.0581,  0.0739],\n",
       "          ...,\n",
       "          [ 0.0423, -0.0998,  0.0988,  ..., -0.0925, -0.0815,  0.0372],\n",
       "          [-0.0088, -0.0204, -0.0228,  ..., -0.0246, -0.0454, -0.1159],\n",
       "          [-0.0582, -0.0503, -0.0417,  ...,  0.0679,  0.0688, -0.0513]],\n",
       "         requires_grad=True)),\n",
       " ('process_tabular.full_sequence.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0973,  0.0689, -0.0883, -0.1201,  0.1117, -0.0270,  0.0407,  0.0049,\n",
       "           0.1566,  0.0784,  0.0068,  0.0852,  0.1235, -0.1107,  0.0206, -0.0499,\n",
       "          -0.0451,  0.0393, -0.0465,  0.0240,  0.0578,  0.0221,  0.1711,  0.1442,\n",
       "          -0.1215, -0.0125, -0.0592,  0.1053,  0.0357,  0.0311],\n",
       "         requires_grad=True)),\n",
       " ('process_image.model.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.2938]],\n",
       "  \n",
       "           [[ 0.0706]],\n",
       "  \n",
       "           [[-0.1019]]]], requires_grad=True)),\n",
       " ('process_image.model.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.1064], requires_grad=True)),\n",
       " ('process_flattened_image.full_sequence.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-5.4142e-02,  2.5602e-02,  2.7681e-02,  ..., -4.5499e-02,\n",
       "           -3.5546e-02, -3.8713e-02],\n",
       "          [-5.1003e-02, -8.9375e-03, -3.9177e-02,  ...,  6.3676e-02,\n",
       "           -5.0326e-02, -5.0908e-02],\n",
       "          [-7.3417e-04,  4.5929e-02, -2.7422e-02,  ...,  3.3448e-02,\n",
       "            1.6023e-02, -5.2275e-03],\n",
       "          ...,\n",
       "          [ 1.3719e-02, -5.9570e-02,  6.0562e-02,  ...,  4.5657e-02,\n",
       "           -5.9725e-02, -2.8786e-02],\n",
       "          [ 1.0456e-02,  3.7628e-02, -4.0616e-02,  ..., -4.9284e-02,\n",
       "           -2.0493e-02,  8.2170e-04],\n",
       "          [ 6.2238e-02,  3.4636e-02,  2.6700e-02,  ..., -4.0671e-02,\n",
       "           -2.3573e-02, -1.6663e-05]], requires_grad=True)),\n",
       " ('process_flattened_image.full_sequence.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0068,  0.0334,  0.0363, -0.0240,  0.0002,  0.0391, -0.0573, -0.0373,\n",
       "           0.0553,  0.0197,  0.0327, -0.0493, -0.0572, -0.0107, -0.0019,  0.0371,\n",
       "           0.0410,  0.0260,  0.0407,  0.0758,  0.0454,  0.0089,  0.0448, -0.0252,\n",
       "           0.0380,  0.0210, -0.0422,  0.0186, -0.0395,  0.0703],\n",
       "         requires_grad=True)),\n",
       " ('process_flattened_image.full_sequence.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 5.9311e-02,  8.0047e-02, -1.7266e-02, -5.5573e-03,  1.4193e-01,\n",
       "           -6.0268e-03, -6.5617e-02,  1.5621e-01, -9.7728e-02, -1.5363e-03,\n",
       "           -6.8796e-02, -4.9363e-02,  1.3322e-01, -1.3708e-01, -9.7577e-02,\n",
       "           -1.1402e-01, -8.5949e-02, -4.9334e-02, -9.5143e-02, -8.0068e-02,\n",
       "           -9.5743e-02, -5.0580e-02,  1.3825e-01, -4.9212e-02, -7.0780e-02,\n",
       "           -6.8572e-02, -3.6365e-02, -1.6022e-01, -6.5839e-02,  9.3258e-02],\n",
       "          [-1.6230e-02,  1.6639e-01,  1.2628e-01,  4.5747e-02,  7.3017e-02,\n",
       "           -4.0019e-02, -1.3827e-01,  4.8147e-02, -1.2632e-01, -1.3569e-02,\n",
       "            1.4622e-01,  5.6030e-02, -3.8606e-02, -1.5905e-01,  9.9182e-02,\n",
       "            1.8615e-02, -9.0247e-02,  8.9274e-02,  1.3713e-01, -2.1037e-02,\n",
       "            1.0670e-01,  1.4419e-01, -1.2659e-01,  1.6003e-01,  2.8264e-03,\n",
       "            1.2846e-01,  4.2026e-02,  1.5987e-02, -7.6439e-02, -1.3468e-01],\n",
       "          [ 1.5732e-01,  9.6533e-02,  4.5319e-02, -1.1434e-01,  1.4462e-01,\n",
       "            1.4531e-01, -1.7029e-01, -1.3397e-01, -2.5741e-02, -1.5939e-01,\n",
       "            1.4243e-01, -5.3107e-02,  2.6490e-02,  2.8840e-02, -1.3996e-01,\n",
       "            9.7501e-02,  1.3280e-02, -1.4878e-01, -1.2485e-01, -9.0275e-02,\n",
       "            1.5865e-02, -8.4216e-02,  6.9351e-02,  6.0115e-02,  9.8910e-02,\n",
       "           -1.1767e-01,  1.2295e-02,  1.1165e-01,  4.3035e-02,  1.0179e-01],\n",
       "          [-2.9648e-03,  1.5949e-01, -5.0478e-02, -1.7286e-01, -8.2661e-02,\n",
       "           -1.1305e-01, -1.8867e-02,  2.5925e-02, -5.6918e-02, -1.6207e-01,\n",
       "            8.8332e-02,  1.2633e-01, -1.1376e-02, -7.7998e-02, -1.2203e-01,\n",
       "            2.4672e-02,  1.1016e-01, -5.0440e-02,  6.7858e-02,  4.2869e-02,\n",
       "            6.7697e-02,  1.2757e-01, -7.3623e-02,  8.3773e-02,  1.5803e-02,\n",
       "            4.2977e-02,  1.6287e-01, -1.3981e-01,  1.0942e-01,  8.7171e-02],\n",
       "          [-1.1594e-01,  1.0158e-02,  1.7306e-01,  1.6417e-01, -9.3881e-02,\n",
       "            1.3716e-01,  4.6330e-02, -8.4616e-02,  4.9376e-02,  1.2239e-01,\n",
       "            6.2227e-03,  7.4819e-02,  5.1278e-02, -3.3750e-03,  1.9874e-02,\n",
       "           -8.8226e-02,  2.8577e-02,  1.5394e-01, -9.0267e-02,  1.6146e-01,\n",
       "           -1.6396e-01, -1.5837e-01, -1.0659e-01, -1.1807e-01, -8.2050e-02,\n",
       "            8.6724e-02, -1.2665e-01, -2.1149e-02, -1.6298e-01,  1.5353e-01],\n",
       "          [ 1.3357e-01,  1.2707e-01, -2.0082e-02,  3.4839e-04, -9.4164e-03,\n",
       "            4.2372e-02,  1.3802e-01,  9.7215e-02,  1.3746e-02, -4.0795e-02,\n",
       "            6.1833e-02,  3.1826e-02, -9.6554e-02, -3.7805e-02,  1.5953e-01,\n",
       "           -5.4834e-02,  1.7391e-01, -9.6617e-02,  3.4569e-02,  1.0741e-01,\n",
       "            1.4686e-01,  1.2482e-01, -6.5362e-03, -8.1160e-02,  1.5748e-01,\n",
       "           -1.7091e-01, -9.3914e-02,  1.2559e-01,  9.3604e-02, -1.5146e-02],\n",
       "          [-1.0282e-01, -8.2859e-02, -1.6744e-01,  6.9020e-03,  8.0345e-02,\n",
       "           -9.1430e-02, -1.4228e-01, -3.3685e-02,  5.3245e-02, -1.4088e-01,\n",
       "           -1.0725e-01,  3.0685e-02, -6.7793e-02,  1.3954e-01,  1.5154e-01,\n",
       "            1.0232e-01, -5.1240e-02, -1.1475e-01,  8.0035e-02,  3.9341e-03,\n",
       "            1.4015e-01, -4.3644e-02,  1.3023e-01,  1.1380e-01,  1.6494e-01,\n",
       "           -1.0504e-01,  6.2453e-02, -1.4400e-01, -9.1873e-03,  4.8039e-02],\n",
       "          [-1.3555e-01, -6.0970e-02,  6.1930e-02,  1.3687e-01,  5.4907e-02,\n",
       "           -3.3750e-03, -6.5753e-02,  1.5805e-02, -5.6654e-02, -1.6447e-01,\n",
       "           -9.8478e-03,  1.7030e-01, -7.6236e-04,  4.9567e-02,  1.5519e-01,\n",
       "            1.7580e-01,  5.5431e-02,  1.1267e-01, -1.3022e-01,  5.5026e-02,\n",
       "           -1.0055e-01, -1.7159e-01, -8.5054e-02,  1.5691e-01,  1.1578e-01,\n",
       "            8.7609e-02, -1.5543e-01, -1.6727e-01, -2.4837e-02, -4.7588e-02],\n",
       "          [-1.2952e-01,  7.4080e-02, -1.5809e-01, -2.3415e-02,  1.0507e-01,\n",
       "            1.3741e-01,  1.3287e-01,  2.1220e-02,  1.0501e-01,  7.4718e-02,\n",
       "           -2.2557e-02,  3.4515e-02,  1.5888e-01, -2.3293e-02, -8.4471e-02,\n",
       "           -4.9286e-02,  2.0656e-02,  3.1056e-02,  7.2712e-03,  1.1501e-01,\n",
       "           -1.7188e-01, -8.1204e-02, -1.7663e-02,  1.6233e-01, -1.0296e-01,\n",
       "            1.1130e-03,  5.3266e-02,  3.4191e-02, -7.2341e-02,  1.2341e-01],\n",
       "          [-1.0734e-01,  8.4051e-02, -1.2165e-01, -8.3543e-02,  5.9097e-02,\n",
       "            1.1485e-01,  2.8298e-02,  4.0856e-02, -2.0746e-02, -1.8404e-02,\n",
       "            7.8892e-02,  6.7276e-02, -1.3241e-01, -6.6984e-02,  7.6815e-02,\n",
       "           -9.5583e-02, -2.7662e-02,  9.6610e-02, -2.3302e-04,  3.1958e-02,\n",
       "            1.4066e-01,  3.2807e-02,  1.3331e-01, -8.5994e-02,  3.4125e-02,\n",
       "           -1.7710e-02, -1.4149e-01,  7.3593e-02,  3.8636e-02,  1.2712e-01],\n",
       "          [-1.7437e-01, -1.4698e-01,  9.2566e-02, -3.4657e-02,  1.5119e-01,\n",
       "            3.8351e-02, -1.5237e-01,  1.1226e-01,  1.1036e-01, -1.6566e-01,\n",
       "           -1.1862e-01, -2.1428e-02, -6.6487e-02,  1.6832e-01, -1.4658e-01,\n",
       "           -1.2779e-01, -1.2706e-01, -5.3906e-02,  7.9519e-02, -1.2921e-01,\n",
       "            1.4883e-01,  1.6780e-01,  6.4967e-02,  7.2051e-02, -1.4099e-01,\n",
       "            8.3075e-02,  1.8454e-02,  1.7553e-02,  1.2557e-01, -1.1463e-01],\n",
       "          [ 3.5585e-02, -8.8436e-02, -6.2737e-02, -3.6720e-02, -1.0100e-01,\n",
       "            7.4773e-02, -1.7376e-01,  1.4841e-01,  1.7484e-01, -1.3715e-01,\n",
       "           -3.0576e-03,  1.0289e-01, -5.4468e-02,  1.1991e-01, -1.3155e-01,\n",
       "           -1.3481e-01, -5.3896e-03, -1.3850e-01,  4.4713e-02,  8.3680e-02,\n",
       "            1.9780e-02,  2.1381e-02, -6.3931e-03,  9.9304e-02, -1.0028e-01,\n",
       "           -5.7376e-02, -1.4552e-02, -1.7634e-01, -1.2513e-01,  5.1480e-02],\n",
       "          [-5.9753e-02, -1.2460e-01,  5.8512e-02, -1.0011e-01,  1.4845e-01,\n",
       "            1.3219e-01,  2.4673e-03,  6.0557e-02, -3.8052e-02, -7.3374e-02,\n",
       "           -2.9099e-04,  1.2257e-01, -7.1826e-02, -1.5714e-01, -6.2880e-02,\n",
       "           -1.4551e-01,  3.3330e-02, -9.3889e-02, -1.4839e-01,  1.7257e-01,\n",
       "            3.0610e-02,  1.2746e-01,  8.6709e-02, -4.5052e-02,  5.6341e-02,\n",
       "           -1.3738e-01,  1.1406e-01, -6.1892e-02, -1.1240e-01,  3.2118e-02],\n",
       "          [-8.6144e-02, -4.7655e-02, -4.1631e-02,  1.6468e-01,  1.5613e-01,\n",
       "            1.3089e-01,  4.0243e-02,  1.2700e-01, -1.1860e-01, -1.3513e-01,\n",
       "           -1.1482e-01,  2.3140e-02, -1.8991e-02, -6.2501e-02, -1.3626e-03,\n",
       "           -1.3339e-01,  7.3527e-02, -5.3517e-02, -1.3821e-01, -1.3142e-01,\n",
       "           -7.6495e-02,  5.8535e-02, -7.5315e-02, -1.7199e-01,  4.5416e-02,\n",
       "            1.7073e-01,  1.6212e-01, -2.9075e-02, -1.6713e-01, -1.5869e-01],\n",
       "          [ 6.9062e-02, -1.5207e-03,  1.1096e-01, -1.0962e-01, -5.3966e-02,\n",
       "           -4.6933e-02,  5.3320e-02,  1.7457e-02, -1.5730e-02, -1.1310e-01,\n",
       "            1.5128e-01, -1.0044e-01, -8.7149e-02,  8.8938e-02, -8.8394e-05,\n",
       "            5.8534e-02, -3.1984e-03,  5.5162e-02, -5.4457e-02,  2.8455e-02,\n",
       "           -1.6969e-01,  1.1845e-01,  1.6044e-01,  1.3623e-01,  1.6489e-01,\n",
       "            1.9343e-02, -1.9020e-02,  1.6262e-01,  2.6924e-02,  1.0880e-01],\n",
       "          [ 1.4396e-01,  1.0159e-01,  1.6393e-01,  4.8366e-02, -4.5396e-02,\n",
       "            2.9819e-02,  1.3597e-01, -6.5361e-02, -6.2552e-02, -1.3699e-01,\n",
       "           -2.4306e-02, -4.8148e-02, -7.6549e-02,  1.4345e-01,  1.6969e-01,\n",
       "           -1.1130e-01,  1.7457e-01, -1.7567e-01, -5.6096e-03, -3.8425e-02,\n",
       "            1.7355e-01,  6.9044e-02, -1.4886e-02,  1.5229e-01, -3.9523e-02,\n",
       "           -7.1613e-02,  7.4517e-02,  1.5292e-01,  1.6871e-01,  1.5386e-02],\n",
       "          [-1.5442e-02, -1.1879e-01, -1.0253e-01,  3.8393e-02, -1.7214e-01,\n",
       "            1.6728e-01,  6.7851e-02, -1.2495e-01,  1.0705e-02, -1.4745e-01,\n",
       "           -1.7333e-01, -1.4697e-01, -1.4502e-01,  8.1418e-02,  1.1930e-02,\n",
       "            1.8891e-02, -2.3258e-04,  2.5389e-02, -5.8390e-02, -1.4597e-01,\n",
       "            1.4027e-01, -1.5128e-01,  8.8989e-02,  1.3291e-01, -1.0661e-01,\n",
       "            1.2971e-02,  7.7443e-02, -2.9369e-02, -1.0377e-02, -9.8860e-02],\n",
       "          [-5.5781e-02, -2.0312e-02, -1.7386e-01,  1.0848e-01,  6.5468e-02,\n",
       "            6.7985e-02, -1.3988e-01,  1.6116e-01,  4.4190e-02,  1.6769e-01,\n",
       "            1.2272e-01,  6.8421e-02,  1.0970e-01,  7.5255e-02,  5.3241e-02,\n",
       "           -1.4979e-01, -1.3043e-01, -3.5815e-02,  1.4083e-01, -2.6949e-02,\n",
       "           -7.7381e-02, -4.8323e-02, -1.1967e-01, -5.5895e-02, -1.3961e-02,\n",
       "            1.7305e-01,  6.2181e-02, -1.5682e-01, -8.3048e-03, -5.2363e-03],\n",
       "          [ 1.7153e-01, -8.3610e-02, -1.2279e-01,  5.0490e-02, -1.0005e-01,\n",
       "           -2.3707e-02, -1.3306e-01, -3.1247e-02,  1.4283e-01, -7.5058e-02,\n",
       "            9.9862e-02,  6.3803e-02, -6.5429e-02,  2.9963e-02,  1.1682e-01,\n",
       "            2.6751e-02,  1.1614e-01,  8.4413e-02,  1.5444e-01,  1.0820e-01,\n",
       "            6.3549e-02,  8.5672e-03, -1.3236e-01, -1.0209e-01, -1.3810e-01,\n",
       "            6.6000e-02, -1.0792e-01, -3.6353e-02, -1.6240e-01,  1.7253e-02],\n",
       "          [-3.0215e-02,  1.4063e-01,  6.0009e-02, -5.4222e-02, -1.5277e-01,\n",
       "            1.2061e-01,  1.0219e-01, -1.5546e-01,  6.2688e-02,  1.1022e-01,\n",
       "           -1.8885e-02, -5.5100e-03,  1.1253e-01,  1.0121e-01,  1.0087e-01,\n",
       "           -1.2692e-02,  1.2564e-01, -5.0634e-02, -3.6637e-02,  1.4513e-01,\n",
       "           -1.5183e-01,  1.6334e-01,  9.1254e-02,  2.4794e-02, -1.6966e-01,\n",
       "            1.6612e-01, -1.3396e-01,  1.6137e-01,  9.9402e-02, -4.5047e-02],\n",
       "          [ 1.3239e-01, -8.9984e-02,  1.4920e-01, -1.5660e-01,  1.8967e-02,\n",
       "            1.0201e-01, -8.4819e-02, -7.4468e-02, -1.6989e-01,  7.4161e-02,\n",
       "           -2.2662e-02,  1.5333e-01, -1.1972e-01,  3.0891e-02, -7.7571e-03,\n",
       "           -7.1937e-02,  1.5444e-01, -1.6319e-02,  9.4330e-02, -1.5747e-01,\n",
       "            4.0815e-02, -9.1235e-02,  3.2102e-02, -1.7586e-01, -6.2539e-02,\n",
       "           -7.5942e-02, -8.9559e-02,  7.0959e-02,  7.9228e-02, -7.7679e-02],\n",
       "          [ 5.8814e-02,  1.2114e-02, -9.4185e-02, -8.5890e-02,  1.7083e-01,\n",
       "           -6.9947e-02,  1.1522e-01,  6.9832e-03,  6.1989e-02, -1.2690e-01,\n",
       "            6.2980e-03, -1.1113e-01, -1.6711e-01,  3.8253e-02, -1.2692e-01,\n",
       "           -7.1297e-02, -2.3573e-02, -3.9889e-02,  1.3128e-01, -9.4163e-02,\n",
       "            6.6835e-02, -1.2517e-01, -1.1753e-01, -1.0848e-01,  6.8959e-02,\n",
       "            2.8806e-02, -9.8774e-02, -8.0527e-02, -1.4157e-01,  7.3672e-02],\n",
       "          [ 6.6724e-02,  8.1820e-02, -1.3671e-01,  9.4351e-03, -1.2471e-01,\n",
       "           -4.3363e-02, -1.3604e-01, -8.9463e-02, -1.4654e-01, -1.4683e-01,\n",
       "           -9.5697e-02,  1.5667e-02, -1.5870e-01,  1.9614e-02,  1.0046e-01,\n",
       "            2.9509e-02,  1.6635e-01,  1.1158e-01,  7.0015e-02, -3.0382e-02,\n",
       "           -1.2326e-01, -2.7209e-02,  2.0860e-02, -9.3324e-02, -3.5339e-02,\n",
       "           -1.6982e-01, -1.3873e-01, -7.2364e-02,  1.4964e-01, -1.3907e-01],\n",
       "          [-3.3147e-02, -8.2859e-02,  1.6790e-01, -1.4833e-01,  1.2095e-01,\n",
       "           -1.3274e-01, -1.1222e-01, -1.1802e-02,  1.4855e-01, -5.2332e-02,\n",
       "           -6.0882e-02,  1.3271e-01, -1.3389e-01,  1.3135e-01,  3.0662e-02,\n",
       "            1.0047e-01, -1.2394e-01,  9.2519e-02,  7.1968e-02,  1.0226e-01,\n",
       "            6.3337e-02,  4.0300e-02,  1.4753e-01,  7.3337e-02, -3.7943e-02,\n",
       "            1.5321e-01, -4.3967e-02,  8.2671e-03, -4.6721e-02, -7.8080e-02],\n",
       "          [ 1.7015e-01,  1.1338e-01, -1.7058e-01, -7.8901e-02,  1.0664e-01,\n",
       "            3.1387e-03,  5.4952e-02, -1.3586e-01, -1.3845e-01,  1.1475e-01,\n",
       "            9.1525e-02, -1.3585e-01,  4.5352e-02,  1.3204e-01,  1.4887e-01,\n",
       "           -1.4173e-03,  2.6116e-02,  7.7517e-03,  8.0616e-02,  4.3180e-02,\n",
       "           -6.9991e-02, -1.0527e-01, -3.0162e-02, -2.3971e-03,  1.0860e-01,\n",
       "            1.5997e-01, -6.7412e-02, -1.0080e-01,  7.5744e-03,  1.3905e-01],\n",
       "          [-1.7447e-01, -8.9222e-03,  1.1954e-02,  9.1861e-02, -6.2730e-02,\n",
       "           -3.3011e-02,  4.6215e-02,  1.3833e-01,  9.5533e-02, -1.5761e-01,\n",
       "            8.9679e-03,  1.2050e-01, -4.6130e-02,  3.6003e-02,  1.0740e-01,\n",
       "            1.0053e-01,  1.1581e-02,  1.1072e-01, -4.1635e-02,  6.3388e-02,\n",
       "            9.3465e-02, -9.5210e-02, -8.6809e-02, -9.8918e-02,  1.5498e-01,\n",
       "            1.5889e-01,  1.7349e-01,  3.5182e-02,  5.5615e-03, -1.2118e-01],\n",
       "          [-1.3471e-01,  1.7406e-01, -1.2436e-01, -1.5776e-01,  8.9108e-02,\n",
       "           -1.1417e-01, -1.4717e-01, -3.9138e-02, -7.1535e-02,  4.9244e-02,\n",
       "           -1.4325e-01, -1.1330e-01, -4.1530e-02, -6.1048e-02, -2.6590e-02,\n",
       "            8.0869e-04, -7.1251e-02, -6.2085e-03, -6.7782e-03, -1.4568e-01,\n",
       "            1.0598e-01, -4.0905e-02, -2.5282e-02, -7.1759e-02, -7.2632e-02,\n",
       "            1.5216e-02, -7.2248e-02, -8.0369e-02,  1.5017e-01,  1.5532e-01],\n",
       "          [-1.5146e-01, -1.4669e-02, -1.2723e-01,  3.1352e-02, -1.1710e-01,\n",
       "           -1.0205e-01,  9.9115e-02, -8.4573e-02,  1.2002e-01,  1.3079e-01,\n",
       "           -1.3014e-01,  3.2217e-02, -6.6169e-02, -1.2432e-01, -7.2530e-02,\n",
       "           -9.9929e-02,  4.5749e-02, -1.1831e-01,  3.7070e-02,  4.1349e-02,\n",
       "            1.1698e-01,  8.0338e-03,  6.3053e-02, -8.5925e-03, -3.9260e-02,\n",
       "           -1.5336e-02,  2.1390e-02,  1.0251e-01, -1.2796e-02, -1.0520e-01],\n",
       "          [-1.3573e-01,  1.1699e-01, -7.0753e-03,  1.2655e-01,  1.4276e-01,\n",
       "           -1.3253e-01,  3.5262e-03, -1.7408e-01, -1.0566e-01,  9.5437e-02,\n",
       "           -1.7514e-01, -1.8364e-03, -9.6609e-02, -1.1395e-01, -8.5282e-02,\n",
       "           -3.7119e-02, -1.7903e-02,  4.0891e-02,  1.3628e-01,  4.6541e-02,\n",
       "           -1.5705e-01, -6.6981e-02, -5.5879e-02, -4.9768e-02,  5.5698e-02,\n",
       "           -1.6253e-01,  6.6097e-02,  5.9118e-02, -8.1050e-02, -7.2617e-02],\n",
       "          [-1.0833e-01,  1.5763e-02,  2.1784e-02, -1.7399e-02, -7.9164e-02,\n",
       "           -2.1745e-02,  5.6389e-02,  1.0393e-01, -1.5528e-01,  6.1296e-02,\n",
       "           -6.4066e-02,  1.4639e-01,  4.2794e-02, -7.0493e-02, -6.3822e-02,\n",
       "           -8.9424e-02,  8.1128e-02, -3.2154e-03, -4.9739e-02, -5.1664e-02,\n",
       "            4.5053e-02, -1.6847e-01, -2.3692e-02,  1.5213e-01,  1.1507e-01,\n",
       "           -3.8836e-02,  1.2012e-01, -1.4508e-02, -1.7235e-01, -1.3349e-01]],\n",
       "         requires_grad=True)),\n",
       " ('process_flattened_image.full_sequence.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1490, -0.0550, -0.1578,  0.1703,  0.1301,  0.1011,  0.0113,  0.1113,\n",
       "          -0.1519,  0.1098, -0.1449, -0.0004,  0.0797,  0.0435, -0.0982, -0.1542,\n",
       "          -0.0332, -0.1239,  0.2147, -0.0009, -0.0002, -0.0606,  0.0440,  0.1413,\n",
       "          -0.0793, -0.0615,  0.0512,  0.1162,  0.0678,  0.1767],\n",
       "         requires_grad=True)),\n",
       " ('process_both.full_sequence.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0632, -0.0123, -0.0306,  ..., -0.1040, -0.0864, -0.0021],\n",
       "          [ 0.0996,  0.0742, -0.0817,  ...,  0.1733, -0.1060,  0.1130],\n",
       "          [-0.0879, -0.1037, -0.0137,  ...,  0.0502, -0.0020,  0.0336],\n",
       "          ...,\n",
       "          [-0.0890, -0.0820,  0.0294,  ...,  0.1080, -0.0708, -0.1133],\n",
       "          [-0.0106, -0.0131,  0.0164,  ..., -0.0354, -0.0710,  0.0804],\n",
       "          [-0.0768, -0.1105, -0.0761,  ..., -0.0169, -0.0354, -0.0515]],\n",
       "         requires_grad=True)),\n",
       " ('process_both.full_sequence.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1436, -0.0346, -0.0830,  0.0827, -0.0219, -0.0492,  0.1216,  0.0838,\n",
       "          -0.0325,  0.1249,  0.1363, -0.0849,  0.0655, -0.1092,  0.0341,  0.1219,\n",
       "          -0.0512,  0.2851, -0.1090,  0.2291, -0.1001, -0.1158,  0.0716,  0.0913,\n",
       "          -0.0776,  0.0838,  0.1069, -0.0627,  0.1239,  0.1245],\n",
       "         requires_grad=True)),\n",
       " ('process_both.full_sequence.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 4.2762e-02, -6.0712e-02, -1.3838e-01, -1.8690e-01, -8.2576e-02,\n",
       "            9.1506e-02,  1.3219e-01,  3.6514e-02,  7.5151e-03,  8.0264e-02,\n",
       "            1.3507e-01,  8.8157e-02,  4.1719e-02, -5.6814e-02,  1.9945e-02,\n",
       "           -1.7370e-01,  4.3809e-02, -2.6487e-02, -1.7221e-01, -1.0911e-02,\n",
       "           -9.3932e-02,  1.2640e-01, -6.9610e-02, -1.1302e-01,  4.3265e-04,\n",
       "           -9.1990e-03,  1.1506e-01, -1.6750e-01, -2.4149e-02, -1.2898e-01],\n",
       "          [-2.5811e-01, -1.8630e-02, -4.6614e-02,  4.3827e-02, -1.5055e-01,\n",
       "            8.6921e-02,  2.5934e-01, -2.7099e-03,  1.3164e-01, -1.6540e-01,\n",
       "            1.2309e-01,  2.4933e-04,  9.3108e-02, -9.3203e-02,  4.4782e-02,\n",
       "            3.5878e-01,  1.6712e-01, -3.8071e-01,  1.6069e-01, -2.8127e-01,\n",
       "            1.1165e-01,  1.7519e-01, -2.7300e-01,  7.5940e-01,  1.1986e-01,\n",
       "            2.8078e-01, -6.0703e-02,  1.5787e-01,  2.8524e-01,  4.7361e-02],\n",
       "          [-2.4228e-01,  3.2423e-01, -1.2743e-02,  3.2033e-01,  1.0738e-01,\n",
       "           -1.0165e-01,  3.3417e-01,  3.6742e-01,  1.8949e-01,  1.8364e-01,\n",
       "           -2.7350e-01,  7.3462e-03, -2.0588e-01,  8.0612e-02, -3.5173e-02,\n",
       "            8.7454e-02, -8.8738e-02,  4.2669e-01, -2.1288e-02, -3.4154e-01,\n",
       "            3.1733e-02,  7.1285e-02, -1.2498e-01, -2.4536e-01, -8.0422e-02,\n",
       "            4.2853e-01,  3.4953e-01, -6.7432e-02, -2.1556e-01, -1.2394e-01]],\n",
       "         requires_grad=True)),\n",
       " ('process_both.full_sequence.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0845,  0.1672,  0.1780], requires_grad=True))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_image.Nout_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_image.Nout_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(40,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Sequential(nn.MaxPool2d(kernel_size = 2, stride = 1),\n",
    "                                           nn.LeakyReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 15, 15])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.flatten(x(y), start_dim = 1, end_dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 225])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([225])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
